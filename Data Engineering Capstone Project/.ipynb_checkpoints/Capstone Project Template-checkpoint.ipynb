{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Udacity Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "- This project aims to be able to answers questions on US immigration such as what are the most popular cities for immigration, what is the gender distribution of the immigrants, what is the visa type distribution of the immigrants, what is the average age per immigrant and what is the average temperature per month per city. We extract data from 3 different sources, the I94 immigration dataset of 2016, city temperature data from Kaggle and US city demographic data from OpenSoft. We design 4 dimension tables: Cities, immigrants, monthly average city temperature and time, and 1 fact table: Immigration. We use Spark for ETL jobs and store the results in parquet for downstream analysis.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "- This project aims to be able to answers questions on US immigration such as what are the most popular cities for immigration, what is the gender distribution of the immigrants, what is the visa type distribution of the immigrants, what is the average age per immigrant and what is the average temperature per month per city. We extract data from 3 different sources, the I94 immigration dataset of 2016, city temperature data from Kaggle and US city demographic data from OpenSoft. We design 4 dimension tables: Cities, immigrants, monthly average city temperature and time, and 1 fact table: Immigration. We use Spark for ETL jobs and store the results in parquet for downstream analysis.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "* I94 immigration data comes from theUS National Tourism and Trade Office website. It is provided in SAS7BDAT format which is a binary database storage format.\n",
    "\n",
    "The temperature data is a Kaggle data set that includes temperatures in cities around the world. It can be found here: https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data\n",
    "\n",
    "###### Immigration Key Notes:\n",
    "\n",
    "* i94yr = 4 digit year,\n",
    "* i94mon = numeric month,\n",
    "* i94cit = 3 digit code of origin city,\n",
    "* i94port = 3 character code of destination USA city,\n",
    "* arrdate = arrival date in the USA,\n",
    "* i94mode = 1 digit travel code,\n",
    "* depdate = departure date from the USA,\n",
    "* i94visa = reason for immigration, The temperature data set comes from Kaggle. It is in csv format.,\n",
    "\n",
    "###### Temperature Key Notes:\n",
    "\n",
    "* AverageTemperature = average temperature,\n",
    "* City = city name,\n",
    "* Country = country name,\n",
    "* Latitude= latitude,\n",
    "* Longitude = longitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DateType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf, rand\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "import psycopg2\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Spark session with SAS7BDAT jar\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "immigration_df = spark.read.format(\"com.github.saurfang.sas.spark\").load(immigration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "| 18.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MI|20555.0|  57.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1959.0|09302016|  null|  null|     AZ|9.247103803E10|00602|      B1|\n",
      "| 19.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  63.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1953.0|09302016|  null|  null|     AZ|9.247139923E10|00602|      B2|\n",
      "| 20.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  57.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1959.0|09302016|  null|  null|     AZ|9.247161383E10|00602|      B2|\n",
      "| 21.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20553.0|  46.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1970.0|09302016|  null|  null|     AZ|9.247079603E10|00602|      B2|\n",
      "| 22.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20562.0|  48.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1968.0|09302016|  null|  null|     AZ|9.247848973E10|00608|      B1|\n",
      "| 23.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20671.0|  52.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1964.0|09302016|  null|  null|     TK|9.250139443E10|00001|      B2|\n",
      "| 24.0|2016.0|   4.0| 101.0| 101.0|    TOR|20545.0|    1.0|     MO|20554.0|  33.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1983.0|09302016|  null|  null|     MQ|9.249090503E10|03348|      B2|\n",
      "| 27.0|2016.0|   4.0| 101.0| 101.0|    BOS|20545.0|    1.0|     MA|20549.0|  58.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1958.0|04062016|     M|  null|     LH|9.247876383E10|00422|      B1|\n",
      "| 28.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20549.0|  56.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1960.0|04062016|     F|  null|     LH|9.247890033E10|00422|      B1|\n",
      "| 29.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20561.0|  62.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1954.0|09302016|     M|  null|     AZ|9.250378143E10|00614|      B2|\n",
      "| 30.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NJ|20578.0|  49.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1967.0|09302016|     M|  null|     OS|9.247020943E10|00089|      B2|\n",
      "| 31.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NY|20611.0|  43.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1973.0|09302016|     M|  null|     OS|9.247128923E10|00089|      B2|\n",
      "| 33.0|2016.0|   4.0| 101.0| 101.0|    HOU|20545.0|    1.0|     TX|20554.0|  53.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1963.0|09302016|     F|  null|     TK|9.250930163E10|00033|      B2|\n",
      "| 34.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     CT|   null|  48.0|    2.0|  1.0|20160401|     TIA| null|      G|   null|   null|   null| 1968.0|09302016|     M|  null|     AZ|9.247042023E10|00602|      B2|\n",
      "| 35.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     CT|   null|  74.0|    2.0|  1.0|20160401|     TIA| null|      T|   null|   null|   null| 1942.0|09302016|     F|  null|     TK|  6.69712185E8|    1|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the temperature data\n",
    "temperature_data = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temperature = spark.read.format(\"csv\").option(\"delimiter\", \",\").option(\"header\", \"true\").load(temperature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temperature.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read demographics data\n",
    "demo_fname = \"us-cities-demographics.csv\"\n",
    "demo_df = spark.read.format(\"csv\").option(\"delimiter\", \";\").option(\"header\", \"true\").load(demo_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|         State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|      Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy| Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|       Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|    California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|    New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "|          Peoria|      Illinois|      33.1|          56229|            62432|          118661|              6634|        7517|                   2.4|        IL|American Indian a...| 1343|\n",
      "|        Avondale|       Arizona|      29.1|          38712|            41971|           80683|              4815|        8355|                  3.18|        AZ|Black or African-...|11592|\n",
      "|     West Covina|    California|      39.8|          51629|            56860|          108489|              3800|       37038|                  3.56|        CA|               Asian|32716|\n",
      "|        O'Fallon|      Missouri|      36.0|          41762|            43270|           85032|              5783|        3269|                  2.77|        MO|  Hispanic or Latino| 2583|\n",
      "|      High Point|North Carolina|      35.5|          51751|            58077|          109828|              5204|       16315|                  2.65|        NC|               Asian|11060|\n",
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read airport_codes data\n",
    "airport_codes = \"airport-codes_csv.csv\"\n",
    "airport_df = spark.read.format(\"csv\").option(\"delimiter\", \",\").option(\"header\", \"true\").load(airport_codes)\n",
    "airport_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Explore and Assess the Data\n",
    "\n",
    "### Data Exploration & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659\n"
     ]
    }
   ],
   "source": [
    "# Create list of valid ports\n",
    "i94_sas_label_descriptions_fname = \"I94_SAS_Labels_Descriptions.SAS\"\n",
    "with open(i94_sas_label_descriptions_fname) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "re_compiled = re.compile(r\"\\'(.*)\\'.*\\'(.*)\\'\")\n",
    "valid_ports = {}\n",
    "for line in lines[302:961]:\n",
    "    results = re_compiled.search(line)\n",
    "    valid_ports[results.group(1)] = results.group(2)\n",
    "print(len(valid_ports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "['MD' 'MA' 'AL' 'CA' 'NJ' 'IL' 'AZ' 'MO' 'NC' 'PA' 'KS' 'FL' 'TX' 'VA' 'NV'\n",
      " 'CO' 'MI' 'CT' 'MN' 'UT' 'AR' 'TN' 'OK' 'WA' 'NY' 'GA' 'NE' 'KY' 'SC' 'LA'\n",
      " 'NM' 'IA' 'RI' 'PR' 'DC' 'WI' 'OR' 'NH' 'ND' 'DE' 'OH' 'ID' 'IN' 'AK' 'MS'\n",
      " 'HI' 'SD' 'ME' 'MT']\n"
     ]
    }
   ],
   "source": [
    "# Create list of valid states\n",
    "valid_states = demo_df.toPandas()[\"State Code\"].unique()\n",
    "print(len(valid_states))\n",
    "print(valid_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, col, udf, year, month, avg, round, dayofweek, weekofyear, isnull\n",
    "from pyspark.sql.types import StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create udf to convert SAS date to PySpark date \n",
    "@udf(StringType())\n",
    "def convert_datetime(x):\n",
    "    if x:\n",
    "        return (datetime(1960, 1, 1).date() + timedelta(x)).isoformat()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create udf to validate state\n",
    "@udf(StringType())\n",
    "def validate_state(x):  \n",
    "    if x in valid_states:\n",
    "        return x\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>city_code</th>\n",
       "      <th>state_code</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>WAS</td>\n",
       "      <td>DC</td>\n",
       "      <td>34.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>383.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>MIA</td>\n",
       "      <td>FL</td>\n",
       "      <td>40.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>TOR</td>\n",
       "      <td>TX</td>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>NEW</td>\n",
       "      <td>NY</td>\n",
       "      <td>49.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1229.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>NYC</td>\n",
       "      <td>CT</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        date city_code state_code   age gender  visa_type  count\n",
       "0   168.0  2016-04-01       WAS         DC  34.0      M        2.0    1.0\n",
       "1   383.0  2016-04-01       MIA         FL  40.0      M        2.0    1.0\n",
       "2   608.0  2016-04-01       TOR         TX  45.0      M        1.0    1.0\n",
       "3   930.0  2016-04-01       NEW         NY  49.0      F        2.0    1.0\n",
       "4  1229.0  2016-04-01       NYC         CT  32.0      M        1.0    1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean immigration data\n",
    "\n",
    "# Remove any missing values\n",
    "cleaned_i94_df = immigration_df.dropna(how=\"any\", subset=[\"i94port\", \"i94addr\", \"gender\"])\n",
    "\n",
    "# Extract valid states \n",
    "cleaned_i94_df = cleaned_i94_df.withColumn(\"i94addr\", validate_state(cleaned_i94_df.i94addr))\n",
    "\n",
    "# Convert arrival_date (SAS format) to PySpark format\n",
    "cleaned_i94_df = cleaned_i94_df.withColumn(\"arrdate\", convert_datetime(cleaned_i94_df.arrdate))\n",
    "\n",
    "# only keep us related immigration data\n",
    "cleaned_i94_df = cleaned_i94_df.filter(cleaned_i94_df.i94addr != 'other')\n",
    "\n",
    "staging_i94_df = cleaned_i94_df.select(col(\"cicid\").alias(\"id\"), \n",
    "                                       col(\"arrdate\").alias(\"date\"),\n",
    "                                       col(\"i94port\").alias(\"city_code\"),\n",
    "                                       col(\"i94addr\").alias(\"state_code\"),\n",
    "                                       col(\"i94bir\").alias(\"age\"),\n",
    "                                       col(\"gender\").alias(\"gender\"),\n",
    "                                       col(\"i94visa\").alias(\"visa_type\"),\n",
    "                                       \"count\").drop_duplicates()\n",
    "\n",
    "staging_i94_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: double (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- visa_type: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staging_i94_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temperature.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create udf to map city full name to city port abbreviation\n",
    "\n",
    "@udf(StringType())\n",
    "def city_to_port(city):\n",
    "    for key in valid_ports:\n",
    "        if city.lower() in valid_ports[key].lower():\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>city_code</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>COL</td>\n",
       "      <td>16.9</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>85.21W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>DAB</td>\n",
       "      <td>0.5</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>83.24W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>ONT</td>\n",
       "      <td>6.8</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>116.76W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>POM</td>\n",
       "      <td>5.8</td>\n",
       "      <td>45.81N</td>\n",
       "      <td>123.46W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>PRO</td>\n",
       "      <td>14.3</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>72.00W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month city_code  avg_temperature     lat     long\n",
       "0  2013      4       COL             16.9  32.95N   85.21W\n",
       "1  2013      1       DAB              0.5  39.38N   83.24W\n",
       "2  2013      1       ONT              6.8  34.56N  116.76W\n",
       "3  2013      2       POM              5.8  45.81N  123.46W\n",
       "4  2013      5       PRO             14.3  42.59N   72.00W"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean temperature data\n",
    "\n",
    "# Only use temperatures from United States\n",
    "# Map full name to city port abbreviation\n",
    "# Remove invalid ports\n",
    "cleaned_temp_df = df_temperature.filter(df_temperature[\"Country\"] == \"United States\") \\\n",
    "    .withColumn(\"year\", year(df_temperature['dt'])) \\\n",
    "    .withColumn(\"month\", month(df_temperature[\"dt\"])) \\\n",
    "    .withColumn(\"i94port\", city_to_port(df_temperature[\"City\"])) \\\n",
    "    .withColumn(\"AverageTemperature\", col(\"AverageTemperature\").cast(\"float\")) \\\n",
    "    .dropna(how='any', subset=[\"i94port\"])\n",
    "\n",
    "# Only use temperatures from 2013 (the latest year in the dataset)\n",
    "cleaned_temp_df = cleaned_temp_df.filter(cleaned_temp_df[\"year\"] == 2013)\n",
    "\n",
    "staging_temp_df = cleaned_temp_df.select(col(\"year\"), col(\"month\"), col(\"i94port\").alias(\"city_code\"),\n",
    "                                         round(col(\"AverageTemperature\"), 1).alias(\"avg_temperature\"),\n",
    "                                         col(\"Latitude\").alias(\"lat\"), col(\"Longitude\").alias(\"long\")).drop_duplicates()\n",
    "\n",
    "print(staging_temp_df.count())\n",
    "staging_temp_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- avg_temperature: float (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staging_temp_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State Median Age Male Population  \\\n",
       "0     Silver Spring       Maryland       33.8           40601   \n",
       "1            Quincy  Massachusetts       41.0           44129   \n",
       "2            Hoover        Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga     California       34.5           88127   \n",
       "4            Newark     New Jersey       34.6          138040   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "\n",
       "  Average Household Size State Code                       Race  Count  \n",
       "0                    2.6         MD         Hispanic or Latino  25924  \n",
       "1                   2.39         MA                      White  58723  \n",
       "2                   2.58         AL                      Asian   4759  \n",
       "3                   3.18         CA  Black or African-American  24437  \n",
       "4                   2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "demo_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Define the Data Model\n",
    "### Conceptual Data Model\n",
    "\n",
    "We follow a star schema data model to first create the staging tables and then create the Facts and Dimensions table\n",
    "\n",
    "Here are the tables of the schema:\n",
    "\n",
    "## Staging Tables\n",
    "### staging_i94_df \n",
    "   - id\n",
    "   - date\n",
    "   - city_code\n",
    "   - state_code\n",
    "   - age\n",
    "   - gender\n",
    "   - visa_type\n",
    "   - count\n",
    "\n",
    "### staging_temp_df\n",
    "   - year\n",
    "   - month\n",
    "   - city_code\n",
    "   - city_name\n",
    "   - avg_temperature\n",
    "   - lat\n",
    "   - long\n",
    "\n",
    "### staging_demo_df\n",
    "   - city_code\n",
    "   - state_code\n",
    "   - city_name\n",
    "   - median_age\n",
    "   - pct_male_pop\n",
    "   - pct_female_pop\n",
    "   - pct_veterans\n",
    "   - pct_foreign_born\n",
    "   - pct_native_american\n",
    "   - pct_asian\n",
    "   - pct_black\n",
    "   - pct_hispanic_or_latino\n",
    "   - pct_white\n",
    "   - total_pop\n",
    "    \n",
    "## Dimension Tables\n",
    "### immigrant_df\n",
    "   - id\n",
    "   - gender\n",
    "   - age\n",
    "   - visa_type\n",
    "\n",
    "### city_df\n",
    "   - city_code\n",
    "   - state_code\n",
    "   - city_name\n",
    "   - median_age\n",
    "   - pct_male_pop\n",
    "   - pct_female_pop\n",
    "   - pct_veterans\n",
    "   - pct_foreign_born\n",
    "   - pct_native_american\n",
    "   - pct_asian\n",
    "   - pct_black\n",
    "   - pct_hispanic_or_latino\n",
    "   - pct_white\n",
    "   - total_pop\n",
    "   - lat\n",
    "   - long\n",
    "\n",
    "### monthly_city_temp_df\n",
    "   - city_code\n",
    "   - year\n",
    "   - month\n",
    "   - avg_temperature\n",
    "    \n",
    "### time_df\n",
    "   - date\n",
    "   - dayofweek\n",
    "   - weekofyear\n",
    "   - month\n",
    "    \n",
    "## Fact Table\n",
    "### immigration_df\n",
    "   - id\n",
    "   - state_code\n",
    "   - city_code\n",
    "   - date\n",
    "   - count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean demographics data\n",
    "\n",
    "# Calculate percentages of numeric columns and create new ones\n",
    "cleaned_demo_df = demo_df.withColumn(\"median_age\", demo_df['Median Age']) \\\n",
    "    .withColumn(\"pct_male_pop\", (demo_df['Male Population'] / demo_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_female_pop\", (demo_df['Female Population'] / demo_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_veterans\", (demo_df['Number of Veterans'] / demo_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_foreign_born\", (demo_df['Foreign-born'] / demo_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_race\", (demo_df['Count'] / demo_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"city_code\", city_to_port(demo_df[\"City\"])) \\\n",
    "    .dropna(how='any', subset=[\"city_code\"])\n",
    "\n",
    "cleaned_demo_df = cleaned_demo_df.select(col(\"City\").alias(\"city_name\"), col(\"State Code\").alias(\"state_code\"), \n",
    "                         \"median_age\", \"pct_male_pop\", \"pct_female_pop\",\"pct_veterans\", \n",
    "                         \"pct_foreign_born\", col(\"Total Population\").alias(\"total_pop\"), \n",
    "                         col(\"Race\").alias(\"race\"), \"pct_race\").drop_duplicates()\n",
    "\n",
    "cleaned_demo_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>state_code</th>\n",
       "      <th>city_name</th>\n",
       "      <th>median_age</th>\n",
       "      <th>pct_male_pop</th>\n",
       "      <th>pct_female_pop</th>\n",
       "      <th>pct_veterans</th>\n",
       "      <th>pct_foreign_born</th>\n",
       "      <th>pct_native_american</th>\n",
       "      <th>pct_asian</th>\n",
       "      <th>pct_black</th>\n",
       "      <th>pct_hispanic_or_latino</th>\n",
       "      <th>pct_white</th>\n",
       "      <th>total_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TUC</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>33.6</td>\n",
       "      <td>49.8</td>\n",
       "      <td>50.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>43.5</td>\n",
       "      <td>76.1</td>\n",
       "      <td>531674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCA</td>\n",
       "      <td>TX</td>\n",
       "      <td>Allen</td>\n",
       "      <td>37.2</td>\n",
       "      <td>52.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>71.2</td>\n",
       "      <td>98138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CRP</td>\n",
       "      <td>TX</td>\n",
       "      <td>Corpus Christi</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>61.9</td>\n",
       "      <td>90.3</td>\n",
       "      <td>324082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FMY</td>\n",
       "      <td>FL</td>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>37.3</td>\n",
       "      <td>49.8</td>\n",
       "      <td>50.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>67.8</td>\n",
       "      <td>74015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORL</td>\n",
       "      <td>FL</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>33.1</td>\n",
       "      <td>48.3</td>\n",
       "      <td>51.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>25.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>66.1</td>\n",
       "      <td>270917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LOS</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>50.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>48.8</td>\n",
       "      <td>54.8</td>\n",
       "      <td>3971896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRO</td>\n",
       "      <td>RI</td>\n",
       "      <td>Providence</td>\n",
       "      <td>29.9</td>\n",
       "      <td>49.7</td>\n",
       "      <td>50.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>17.1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>54.6</td>\n",
       "      <td>179204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CID</td>\n",
       "      <td>IA</td>\n",
       "      <td>Cedar Rapids</td>\n",
       "      <td>36.2</td>\n",
       "      <td>48.4</td>\n",
       "      <td>51.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>89.6</td>\n",
       "      <td>130405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SPI</td>\n",
       "      <td>IL</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>38.8</td>\n",
       "      <td>47.2</td>\n",
       "      <td>52.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>77.2</td>\n",
       "      <td>117809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>POM</td>\n",
       "      <td>OR</td>\n",
       "      <td>Portland</td>\n",
       "      <td>36.7</td>\n",
       "      <td>49.6</td>\n",
       "      <td>50.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>82.9</td>\n",
       "      <td>632187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_code state_code       city_name median_age  pct_male_pop  \\\n",
       "0       TUC         AZ          Tucson       33.6          49.8   \n",
       "1       MCA         TX           Allen       37.2          52.3   \n",
       "2       CRP         TX  Corpus Christi       35.0          49.5   \n",
       "3       FMY         FL      Fort Myers       37.3          49.8   \n",
       "4       ORL         FL         Orlando       33.1          48.3   \n",
       "5       LOS         CA     Los Angeles       35.0          49.3   \n",
       "6       PRO         RI      Providence       29.9          49.7   \n",
       "7       CID         IA    Cedar Rapids       36.2          48.4   \n",
       "8       SPI         IL     Springfield       38.8          47.2   \n",
       "9       POM         OR        Portland       36.7          49.6   \n",
       "\n",
       "   pct_female_pop  pct_veterans  pct_foreign_born  pct_native_american  \\\n",
       "0            50.2           7.2               7.2                  4.6   \n",
       "1            47.7           3.6               3.6                  0.2   \n",
       "2            50.5           7.7               7.7                  0.9   \n",
       "3            50.2           5.8               5.8                  NaN   \n",
       "4            51.7           4.7               4.7                  0.9   \n",
       "5            50.7           2.2               2.2                  1.6   \n",
       "6            50.3           2.8               2.8                  2.3   \n",
       "7            51.6           6.0               6.0                  1.0   \n",
       "8            52.8           6.4               6.4                  1.4   \n",
       "9            50.4           4.7               4.7                  2.4   \n",
       "\n",
       "   pct_asian  pct_black  pct_hispanic_or_latino  pct_white total_pop  \n",
       "0        4.6        6.4                    43.5       76.1    531674  \n",
       "1       16.1       13.4                    10.8       71.2     98138  \n",
       "2        2.8        4.6                    61.9       90.3    324082  \n",
       "3        4.8       23.4                    24.1       67.8     74015  \n",
       "4        4.1       25.1                    33.0       66.1    270917  \n",
       "5       12.9       10.2                    48.8       54.8   3971896  \n",
       "6        7.5       17.1                    43.5       54.6    179204  \n",
       "7        4.1        9.1                     4.1       89.6    130405  \n",
       "8        3.3       21.5                     2.3       77.2    117809  \n",
       "9       10.2        7.3                     9.7       82.9    632187  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot the race column\n",
    "pivot_demo_df = cleaned_demo_df.groupBy(\"city_name\", \"state_code\", \"median_age\", \"pct_male_pop\",\n",
    "                                        \"pct_female_pop\",\"pct_veterans\", \"pct_foreign_born\", \"total_pop\").pivot(\"Race\").avg(\"pct_race\")\n",
    "\n",
    "pivot_demo_df = pivot_demo_df.withColumn(\"city_code\", city_to_port(pivot_demo_df[\"city_name\"])) \\\n",
    "    .dropna(how='any', subset=[\"city_code\"])\n",
    "\n",
    "staging_demo_df = pivot_demo_df.select(\"city_code\", \"state_code\", \"city_name\", \"median_age\",\n",
    "                                    round(col(\"pct_male_pop\"), 1).alias(\"pct_male_pop\"),\n",
    "                                    round(col(\"pct_female_pop\"), 1).alias(\"pct_female_pop\"),\n",
    "                                    round(col(\"pct_veterans\"), 1).alias(\"pct_veterans\"),\n",
    "                                    round(col(\"pct_veterans\"), 1).alias(\"pct_foreign_born\"),\n",
    "                                    round(col(\"American Indian and Alaska Native\"), 1).alias(\"pct_native_american\"),\n",
    "                                    round(col(\"Asian\"), 1).alias(\"pct_asian\"),\n",
    "                                    round(col(\"Black or African-American\"), 1).alias(\"pct_black\"),\n",
    "                                    round(col(\"Hispanic or Latino\"), 1).alias(\"pct_hispanic_or_latino\"),\n",
    "                                    round(col(\"White\"), 1).alias(\"pct_white\"), \"total_pop\")\n",
    "print(staging_demo_df.count())\n",
    "staging_demo_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 4: Run Pipelines to Model the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>visa_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270799.0</td>\n",
       "      <td>F</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275758.0</td>\n",
       "      <td>M</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>445416.0</td>\n",
       "      <td>M</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488015.0</td>\n",
       "      <td>M</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>503609.0</td>\n",
       "      <td>M</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id gender   age  visa_type\n",
       "0  270799.0      F  49.0        2.0\n",
       "1  275758.0      M  50.0        2.0\n",
       "2  445416.0      M  69.0        1.0\n",
       "3  488015.0      M   6.0        2.0\n",
       "4  503609.0      M  21.0        2.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigrant_df = staging_i94_df.select(\"id\", \"gender\", \"age\", \"visa_type\").drop_duplicates()\n",
    "immigrant_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create dimension table for city\n",
    "\n",
    "city_df = staging_demo_df.join(staging_temp_df, \"city_code\") \\\n",
    "    .select(\"city_code\", \"state_code\", \"city_name\", \"median_age\", \"pct_male_pop\", \"pct_female_pop\", \"pct_veterans\",\n",
    "           \"pct_foreign_born\", \"pct_native_american\", \"pct_asian\", \"pct_black\",\n",
    "           \"pct_hispanic_or_latino\", \"pct_white\", \"total_pop\", \"lat\", \"long\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>state_code</th>\n",
       "      <th>city_name</th>\n",
       "      <th>median_age</th>\n",
       "      <th>pct_male_pop</th>\n",
       "      <th>pct_female_pop</th>\n",
       "      <th>pct_veterans</th>\n",
       "      <th>pct_foreign_born</th>\n",
       "      <th>pct_native_american</th>\n",
       "      <th>pct_asian</th>\n",
       "      <th>pct_black</th>\n",
       "      <th>pct_hispanic_or_latino</th>\n",
       "      <th>pct_white</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRO</td>\n",
       "      <td>TX</td>\n",
       "      <td>Brownsville</td>\n",
       "      <td>30.6</td>\n",
       "      <td>47.7</td>\n",
       "      <td>52.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>92.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>183888</td>\n",
       "      <td>26.52N</td>\n",
       "      <td>96.72W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSV</td>\n",
       "      <td>WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>30.7</td>\n",
       "      <td>49.2</td>\n",
       "      <td>50.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>82.1</td>\n",
       "      <td>248956</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>85.62W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33.8</td>\n",
       "      <td>48.3</td>\n",
       "      <td>51.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>52.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.3</td>\n",
       "      <td>463875</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>83.68W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Newark</td>\n",
       "      <td>34.6</td>\n",
       "      <td>49.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>51.4</td>\n",
       "      <td>35.6</td>\n",
       "      <td>27.1</td>\n",
       "      <td>281913</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>74.56W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NWH</td>\n",
       "      <td>CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>29.9</td>\n",
       "      <td>48.9</td>\n",
       "      <td>51.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>33.3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>43.2</td>\n",
       "      <td>130310</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>72.43W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_code state_code    city_name median_age  pct_male_pop  pct_female_pop  \\\n",
       "0       BRO         TX  Brownsville       30.6          47.7            52.3   \n",
       "1       HSV         WI      Madison       30.7          49.2            50.8   \n",
       "2       ATL         GA      Atlanta       33.8          48.3            51.7   \n",
       "3       NEW         NJ       Newark       34.6          49.0            51.0   \n",
       "4       NWH         CT    New Haven       29.9          48.9            51.1   \n",
       "\n",
       "   pct_veterans  pct_foreign_born  pct_native_american  pct_asian  pct_black  \\\n",
       "0           2.3               2.3                  0.6        0.9        0.7   \n",
       "1           3.9               3.9                  0.9        9.6        8.2   \n",
       "2           4.0               4.0                  1.0        5.2       52.9   \n",
       "3           2.1               2.1                  0.8        2.6       51.4   \n",
       "4           2.0               2.0                  1.7        6.1       33.3   \n",
       "\n",
       "   pct_hispanic_or_latino  pct_white total_pop     lat    long  \n",
       "0                    92.5       95.0    183888  26.52N  96.72W  \n",
       "1                     7.9       82.1    248956  34.56N  85.62W  \n",
       "2                     4.0       42.3    463875  34.56N  83.68W  \n",
       "3                    35.6       27.1    281913  40.99N  74.56W  \n",
       "4                    33.4       43.2    130310  40.99N  72.43W  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create dimension table for monthly city temperature\n",
    "\n",
    "monthly_city_temp_df = staging_temp_df.select(\"city_code\", \"year\", \"month\", \"avg_temperature\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>avg_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAA</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHI</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUR</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RNO</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_code  year  month  avg_temperature\n",
       "0       SAA  2013      6             18.6\n",
       "1       PHI  2013      5             16.6\n",
       "2       BOS  2013      5             14.3\n",
       "3       BUR  2013      3             14.5\n",
       "4       RNO  2013      2              4.7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_city_temp_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create dimension table for time\n",
    "\n",
    "time_df = staging_i94_df.withColumn(\"dayofweek\", dayofweek(\"date\"))\\\n",
    "                .withColumn(\"weekofyear\", weekofyear(\"date\"))\\\n",
    "                .withColumn(\"month\", month(\"date\"))\n",
    "                        \n",
    "time_df = time_df.select(\"date\", \"dayofweek\", \"weekofyear\", \"month\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  dayofweek  weekofyear  month\n",
       "0  2016-04-23          7          16      4\n",
       "1  2016-04-22          6          16      4\n",
       "2  2016-04-08          6          14      4\n",
       "3  2016-04-09          7          14      4\n",
       "4  2016-04-26          3          17      4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create fact table for immigration\n",
    "\n",
    "immigration_df = staging_i94_df.select(\"id\", \"state_code\", \"city_code\", \"date\", \"count\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+----------+-----+\n",
      "|       id|state_code|city_code|      date|count|\n",
      "+---------+----------+---------+----------+-----+\n",
      "|  25716.0|        CA|      LOS|2016-04-01|  1.0|\n",
      "|  56083.0|        HI|      HHW|2016-04-01|  1.0|\n",
      "| 261977.0|        FL|      NYC|2016-04-02|  1.0|\n",
      "| 290139.0|        NY|      NYC|2016-04-02|  1.0|\n",
      "| 487570.0|        HI|      HHW|2016-04-03|  1.0|\n",
      "| 664951.0|        FL|      ORL|2016-04-04|  1.0|\n",
      "| 684099.0|        DC|      WAS|2016-04-04|  1.0|\n",
      "| 694546.0|        CA|      LOS|2016-04-04|  1.0|\n",
      "| 844967.0|        FL|      MIA|2016-04-05|  1.0|\n",
      "|1050785.0|        FL|      DAL|2016-04-06|  1.0|\n",
      "|1161851.0|        PR|      SAJ|2016-04-07|  1.0|\n",
      "|1236994.0|        FL|      FTL|2016-04-07|  1.0|\n",
      "|1542523.0|        FL|      HOU|2016-04-08|  1.0|\n",
      "|1561384.0|        NY|      NYC|2016-04-09|  1.0|\n",
      "|1991713.0|        NY|      NCA|2016-04-11|  1.0|\n",
      "|2020365.0|        GA|      NYC|2016-04-11|  1.0|\n",
      "|2204565.0|        HI|      HHW|2016-04-12|  1.0|\n",
      "|2472975.0|        NJ|      NYC|2016-04-13|  1.0|\n",
      "|2532377.0|        HI|      HHW|2016-04-14|  1.0|\n",
      "|2655381.0|        FL|      ORL|2016-04-14|  1.0|\n",
      "+---------+----------+---------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write dimension tables to parquet\n",
    "immigrant_df.write.mode(\"overwrite\").partitionBy(\"gender\", \"age\").parquet(\"immigrants\")\n",
    "city_df.write.mode(\"overwrite\").partitionBy(\"state_code\").parquet(\"cities\")\n",
    "monthly_city_temp_df.write.mode(\"overwrite\").parquet(\"monthly_city_temperatues\")\n",
    "time_df.write.mode(\"overwrite\").parquet(\"time\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write fact table to parquet\n",
    "immigration_df.write.mode(\"overwrite\").partitionBy(\"state_code\").parquet(\"immigration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 5 - Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data quality check passed\n",
      "dimension tables and fact table exist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "def table_exists(df):\n",
    "    if df is not None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "if table_exists(immigrant_df) & table_exists(city_df) & table_exists(monthly_city_temp_df) & table_exists(time_df) & table_exists(immigration_df):\n",
    "    print(\"data quality check passed\")\n",
    "    print(\"dimension tables and fact table exist\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"data quality check failed\")\n",
    "    print(\"table missing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data quality check passed!\n",
      "dimension tables and fact table contain records\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def table_not_empty(df):\n",
    "    return df.count() != 0 \n",
    "\n",
    "if table_not_empty(immigrant_df) & table_not_empty(city_df) & table_not_empty(monthly_city_temp_df) & table_not_empty(time_df) & table_not_empty(immigration_df):\n",
    "    print(\"data quality check passed!\")\n",
    "    print(\"dimension tables and fact table contain records\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"data quality check failed!\")\n",
    "    print(\"null records...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
